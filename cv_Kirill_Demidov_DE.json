{
    "$schema": "https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json",
    "basics": {
      "name": "Kirill Demidov",
      "label": "Data Engineer Team Lead",
      "image": "",
      "email": "kirill.demidov@gmail.com",
      "phone": "+972542332917",
      "url": "https://www.linkedin.com/in/kirilldemidov/",
      "summary": "Experienced Data Engineer with expertise in BI, analytics, and large-scale data systems. Proficient in cloud data platforms, pipeline orchestration, and leading engineering teams to build scalable data solutions.",
      "location": {
        "address": "Tel Aviv, Israel",
        "postalCode": "",
        "city": "Tel Aviv",
        "countryCode": "IL",
        "region": "Israel"
      },
      "profiles": [
        {
          "network": "GitHub",
          "username": "kirilldemidov",
          "url": "https://github.com/kirilldemidov"
        },
        {
          "network": "LinkedIn",
          "username": "kirilldemidov",
          "url": "https://www.linkedin.com/in/kirilldemidov/"
        }
      ]
    },
    "work": [
      {
        "name": "Arpeely",
        "location": "Tel Aviv, Israel",
        "description": "AI-driven advertising technology company.",
        "position": "Data Engineer Team Lead",
        "url": "https://arpeely.com",
        "startDate": "2022-07-01",
        "endDate": "2024-07-01",
        "summary": "Leading the data engineering team, building scalable data infrastructure, and developing BI solutions using Google Cloud, BigQuery, and Dataform.",
        "highlights": [
          "Refactored ELT pipelines from custom Python to scalable Dataform solution.",
          "Designed and implemented a corporate Data Warehouse and Data Lake in GCP.",
          "Deployed Looker-based BI system from scratch.",
          "Implemented CI/CD pipelines for DWH and reporting.",
          "Developed a data governance monitoring system."
        ]
      },
      {
        "name": "Tango.me",
        "location": "Tel Aviv, Israel",
        "description": "Live-streaming platform for content creators.",
        "position": "Data Engineer Team Lead",
        "url": "https://www.tango.me",
        "startDate": "2021-07-01",
        "endDate": "2022-07-01",
        "summary": "Managed a team of data engineers and BI developers, implementing data pipelines and analytics solutions in GCP.",
        "highlights": [
          "Led a team of 6 data engineers and BI developers.",
          "Developed corporate Data Lake and Data Warehouse in GCP with Airflow and dbt.",
          "Implemented data governance and data quality monitoring using SelectStar and SodaSQL.",
          "Designed and built analytics and operational reports on Looker."
        ]
      },
      
        {
          "name": "Alterosmart Solutions",
          "location": "Tel Aviv, Israel",
          "description": "Big Data solutions provider specializing in IIoT and analytics.",
          "position": "Big Data Team Lead",
          "url": "https://www.alterosmart.com",
          "startDate": "2019-12-01",
          "endDate": "2021-07-01",
          "summary": "Led the Big Data team, designing and implementing data pipelines, data warehouses, and analytics solutions for industrial IoT systems.",
          "highlights": [
            "Analyzed business requirements, designed, and implemented Big Data modules in PDC systems.",
            "Developed and optimized ETL/ELT processes for IIoT systems (PDC, BMS) using Apache NiFi, Data Build Tool, and Spark.",
            "Designed and implemented an operational Data Warehouse for PDC application data using PostgreSQL.",
            "Built a Data Mart module for Atlassian Jira Software based on PostgreSQL and Cube.js.",
            "Developed and visualized analytical reports for DF data processing."
          ]
        },
        {
          "name": "SafeCharge",
          "location": "Tel Aviv, Israel",
          "description": "A global payments technology company.",
          "position": "Senior BI Developer",
          "url": "https://www.safecharge.com",
          "startDate": "2018-08-01",
          "endDate": "2019-12-01",
          "summary": "Designed and developed BI solutions, Data Marts, and reporting systems, while maintaining ETL processes for internal analytics.",
          "highlights": [
            "Analyzed business requirements and designed Data Marts for internal clients.",
            "Maintained an ETL platform based on SSIS.",
            "Developed a semantic layer using SSAS (OLAP Cube).",
            "Designed and implemented a reporting system using SSRS and Power BI.",
            "Migrated OLAP-based BI system to a Big Data environment using AWS Data Lake (S3), ELT pipelines with Apache NiFi and Spark (PySpark), and MemSQL as the semantic layer."
          ]
        },
        {
          "name": "Data Cube",
          "location": "Tel Aviv, Israel",
          "description": "BI and Big Data consultancy serving enterprise clients.",
          "position": "BI Project Manager / BI & Big Data Engineer",
          "url": "https://www.datacube.co.il",
          "startDate": "2014-01-01",
          "endDate": "2018-08-01",
          "summary": "Managed BI projects and developed BI & Big Data solutions for various enterprises.",
          "highlights": [
            "Managed BI projects from conceptualization to full implementation.",
            "Analyzed business requirements and developed project deliverables.",
            "Maintained ETL platforms using SSIS, Python, and T-SQL.",
            "Designed and implemented Data Marts and Data Warehouses for internal analytics systems.",
            "Developed OLAP and Tabular Cube semantic layers.",
            "Implemented reporting systems using Pyramid BI Office, SSRS, Necto Panorama, Power BI, and Business Objects.",
            "Served major clients including BioCatch, Postal Bank of Israel, Bituach Yashir, Mimun Yashir, MKS Instruments, Taglit Birthright Israel, Panaya, Reuth Medical Rehabilitation Center, Medinol, LiderForex, and Amdocs."
          ]
        },
        {
          "name": "Company for Location and Restitution of Holocaust Victims' Assets",
          "location": "Israel",
          "description": "A governmental organization dedicated to identifying and restituting assets to Holocaust survivors and their heirs.",
          "position": "Head of Data Management and Data Integration Department",
          "url": "https://www.holocaust-assets.org.il",
          "startDate": "2008-01-01",
          "endDate": "2014-01-01",
          "summary": "Led data management initiatives, developed data integration tools, and managed ETL and reporting systems.",
          "highlights": [
            "Developed knowledge management tools using MS SQL Server 2012.",
            "Designed and managed ETL processes for data integration and reporting.",
            "Created, managed, and supported a SharePoint-based database system.",
            "Led a team in developing research projects, providing training, and knowledge sharing."
          ]
        }
      
    ],
    "education": [
      {
        "institution": "Hebrew University of Jerusalem",
        "url": "https://new.huji.ac.il/en",
        "area": "Political Science",
        "studyType": "Master",
        "startDate": "2012-06-01",
        "endDate": "2014-01-01",
        "score": "",
        "courses": []
      },
      {
        "institution": "Hebrew University of Jerusalem",
        "url": "https://new.huji.ac.il/en",
        "area": "Political Science",
        "studyType": "Bachelor",
        "startDate": "2004-06-01",
        "endDate": "2008-01-01",
        "score": "",
        "courses": []
      },
      {
        "institution": "John Bryce College",
        "url": "https://www.johnbryce.co.il",
        "area": "Business Intelligence",
        "studyType": "MCSE Certification",
        "startDate": "2013-06-01",
        "endDate": "2014-01-01",
        "score": "",
        "courses": []
      }
    ],
    "skills": [
      {
        "name": "Data Engineering",
        "level": "Expert",
        "keywords": [
          "BigQuery",
          "PostgreSQL",
          "DuckDB",
          "Dataform",
          "dbt"
        ]
      },
      {
        "name": "Cloud Platforms",
        "level": "Expert",
        "keywords": [
          "Google Cloud Platform",
          "AWS",
          "Cloud Data Lakes"
        ]
      },
      {
        "name": "BI & Analytics",
        "level": "Advanced",
        "keywords": [
          "Looker",
          "Power BI",
          "Data Visualization"
        ]
      },
      {
        "name": "Orchestration & ETL",
        "level": "Advanced",
        "keywords": [
          "Apache Airflow",
          "Apache NiFi",
          "Spark"
        ]
      }
    ],
    "languages": [
      {
        "language": "Hebrew",
        "fluency": "Native speaker"
      },
      {
        "language": "Russian",
        "fluency": "Native speaker"
      },
      {
        "language": "English",
        "fluency": "Fluent"
      }
    ],
    "projects": [
      {
        "name": "Data Lake Implementation",
        "description": "Designed and built a corporate Data Lake for analytics and reporting.",
        "highlights": [
          "Implemented scalable cloud storage solutions.",
          "Optimized data partitioning and query performance.",
          "Automated data ingestion using Apache Airflow."
        ],
        "keywords": [
          "BigQuery",
          "Google Cloud Storage",
          "Apache Airflow"
        ],
        "startDate": "2021-08-01",
        "endDate": "2022-07-01",
        "url": "https://example.com/data-lake",
        "roles": [
          "Tech Lead",
          "Architect"
        ],
        "entity": "Tango.me",
        "type": "Data Engineering"
      },
      {
        "name": "Enterprise BI Deployment",
        "description": "Built an end-to-end BI and reporting system using Looker and Google Cloud.",
        "highlights": [
          "Integrated multiple data sources into Looker.",
          "Designed intuitive dashboards for business users.",
          "Implemented role-based data access security."
        ],
        "keywords": [
          "Looker",
          "Dataform",
          "CI/CD"
        ],
        "startDate": "2022-09-01",
        "endDate": "2023-06-01",
        "url": "https://example.com/bi-deployment",
        "roles": [
          "BI Architect",
          "Data Engineer"
        ],
        "entity": "Arpeely",
        "type": "Business Intelligence"
      }
    ],
    "meta": {
      "canonical": "https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/sample.resume.json",
      "version": "v1.0.0",
      "lastModified": "2025-02-27T15:00:00"
    }
  }